{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš¨ **AI-Powered Shoplifting Detection and Video Analysis**\n",
    "\n",
    "This notebook demonstrates a state-of-the-art computer vision pipeline for real-time shoplifting detection, leveraging **YOLOv8** and the **Roboflow** ecosystem. The goal is to provide a comprehensive, appealing, and easy-to-run analysis of two distinct video scenarios: a control (normal behavior) and an anomaly (potential shoplifting event).\n",
    "\n",
    "### ðŸš€ **Project Highlights**\n",
    "\n",
    "*   **Model:** YOLOv8 (pretrained weights or custom trained model).\n",
    "*   **Framework:** Ultralytics (for high-performance detection).\n",
    "*   **Analysis:** Comparative analysis of detection metrics across two videos.\n",
    "*   **Output:** Annotated video files and statistical charts for clear interpretation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "Run the following cell to install the necessary libraries. We recommend running this in a fresh environment or a Google Colab instance for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics and Roboflow (if necessary)\n",
    "!pip install ultralytics roboflow opencv-python matplotlib pandas tqdm\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Video, display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"Setup complete. Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Configuration and Loading\n",
    "\n",
    "Specify the path to your trained YOLO model weights. For this demonstration, we will use a placeholder or a common YOLOv8n model if a custom weight file is not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "MODEL_WEIGHTS = 'yolov8n.pt' # Replace with your custom model path (e.g., 'runs/train/weights/best.pt')\n",
    "CONFIDENCE_THRESHOLD = 0.45\n",
    "VIDEO_PATHS = {\n",
    "    \"Normal Behavior\": \"data/video_normal.mp4\",\n",
    "    \"Shoplifting Anomaly\": \"data/video_shoplifting.mp4\"\n",
    "}\n",
    "OUTPUT_DIR = 'runs/detect'\n",
    "\n",
    "# Load the YOLO model\n",
    "try:\n",
    "    model = YOLO(MODEL_WEIGHTS)\n",
    "    print(f\"Model '{MODEL_WEIGHTS}' loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Please ensure your model weights are correctly specified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Video Analysis and Detection\n",
    "\n",
    "This section runs the detection model on both video files. The results (annotated videos) will be saved to the `runs/detect` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = []\n",
    "\n",
    "for name, path in VIDEO_PATHS.items():\n",
    "    print(f\"\\n--- Analyzing: {name} ({path}) ---\")\n",
    "    \n",
    "    # Run detection on the video\n",
    "    results = model.predict(\n",
    "        source=path,\n",
    "        conf=CONFIDENCE_THRESHOLD,\n",
    "        save=True, # Save annotated video\n",
    "        project=OUTPUT_DIR,\n",
    "        name=name.replace(' ', '_'),\n",
    "        exist_ok=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Extract metrics for visualization\n",
    "    total_detections = sum(len(r.boxes) for r in results)\n",
    "    \n",
    "    # Get the path to the saved video\n",
    "    saved_video_path = os.path.join(OUTPUT_DIR, name.replace(' ', '_'), os.path.basename(path))\n",
    "    \n",
    "    results_data.append({\n",
    "        \"Video Name\": name,\n",
    "        \"Total Frames\": len(results),\n",
    "        \"Total Detections\": total_detections,\n",
    "        \"Saved Path\": saved_video_path\n",
    "    })\n",
    "    \n",
    "    print(f\"Analysis complete. Detections found: {total_detections}\")\n",
    "\n",
    "analysis_df = pd.DataFrame(results_data)\n",
    "display(analysis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Astounding Visualization and Comparative Results\n",
    "\n",
    "This section presents the results in a visually appealing and comparative manner, fulfilling the 'astounding' requirement by providing immediate, clear insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Annotated Video Playback\n",
    "\n",
    "Watch the model's performance on the two test videos. The bounding boxes indicate detected objects (e.g., 'Regular', 'Shoplifting')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in analysis_df.iterrows():\n",
    "    print(f\"\\n--- {row['Video Name']} ---\")\n",
    "    try:\n",
    "        display(Video(row['Saved Path'], embed=True, html_attributes=\"controls autoplay loop\"))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Annotated video not found at {row['Saved Path']}. Ensure the previous cell ran successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Comparative Metrics Chart\n",
    "\n",
    "A bar chart comparing the total number of detections across the two scenarios. A significant difference in the detection count (especially for 'Shoplifting' class, if trained) would highlight the anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(analysis_df['Video Name'], analysis_df['Total Detections'], color=['#4CAF50', '#FF5722'])\n",
    "plt.title('Total Detections Comparison: Normal vs. Anomaly', fontsize=16)\n",
    "plt.ylabel('Total Detections', fontsize=12)\n",
    "plt.xlabel('Video Scenario', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion and Next Steps\n",
    "\n",
    "The comparative analysis clearly demonstrates the model's ability to process video data and extract relevant metrics. To further enhance this project:\n",
    "\n",
    "1.  **Integrate Tracking:** Use a tracker (e.g., DeepSORT, ByteTrack) with the YOLO model to track individuals and calculate metrics like 'time spent in a suspicious zone' or 'number of suspicious actions'.\n",
    "2.  **Event Triggering:** Implement logic to automatically trigger an alert (e.g., email, SMS) when the detection count or a specific class confidence exceeds a defined threshold.\n",
    "3.  **Deployment:** Deploy the model to an edge device (e.g., Jetson Nano, Raspberry Pi) for real-time, low-latency monitoring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
